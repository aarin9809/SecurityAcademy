{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyNfU/WrmwS+xW5DNhrBgAGx"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"CpTsd2wAAUkd"},"outputs":[],"source":["!pip install roboflow\n","\n","from roboflow import Roboflow\n","rf = Roboflow(api_key=\"mFFA0OPQrCWnnk7kRawr\")\n","project = rf.workspace(\"joaoissamu\").project(\"objectdetect-fs9hx\")\n","version = project.version(1)\n","dataset = version.download(\"yolov5\")\n","\n"]},{"cell_type":"code","source":["pwd"],"metadata":{"id":"sIe_Cc3-AsUX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","\n","if not os.path.exists('content/yolov5'):\n","  !git clone https://github.com/ultralytics/yolov5\n","  %cd yolov5\n","  !pip install -r requirements.txt # install dependencies"],"metadata":{"id":"Xyf9HrLUAzwx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%cat /content/ObjectDetect-1/data.yaml"],"metadata":{"id":"47exdtamBcHC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!python /content/yolov5/train.py --batch 16 --epochs 100 --data \"/content/ObjectDetect-1/data.yaml\" --cfg /content/yolov5/models/yolov5s.yaml  --weights yolov5s.pt --name test_yolov5s_100 --device 0"],"metadata":{"id":"Jm0yS2wIBfjC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from IPython.display import Image\n","\n","Image(filename='/content/yolov5/runs/train/test_yolov5s_1002/train_batch2.jpg', width=900)"],"metadata":{"id":"mA20YMarJ71w"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import glob\n","\n","var_img_list = glob.glob('/content/ObjectDetect-1/valid/images/*')\n","\n","from IPython.display import Image\n","import os\n","\n","val_img_path = var_img_list[0]\n","print(val_img_path)\n","\n","!python detect.py --weights /content/yolov5/runs/train/test_yolov5s_1002/weights/best.pt --img 416 --conf 0.5 --exist-ok --source /content/ObjectDetect-1/valid/images/054376_jpg.rf.89624a42c6101480f64b20371c70a8fe.jpg\n","\n","Image(os.path.join('/content/ObjectDetect-1/valid/images/', os.path.basename(val_img_path)))"],"metadata":{"id":"nGPHnSWzL0Dy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","from PIL import Image\n","import cv2\n","import matplotlib.pyplot as plt\n","import numpy as np\n","from google.colab.patches import cv2_imshow\n","\n","model = torch.hub.load('ultralytics/yolov5', 'custom', path='/content/yolov5/runs/train/test_yolov5s_1002/weights/best.pt')\n","\n","img = Image.open('/content/ObjectDetect-1/valid/images/054376_jpg.rf.89624a42c6101480f64b20371c70a8fe.jpg')\n","\n","results = model(img)"],"metadata":{"collapsed":true,"id":"w0sVntKzEBje"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df = results.pandas().xyxy[0]\n","\n","for index, row in df.iterrows():\n","    x1, y1, x2, y2, confidence, class_id, name = row\n","    print(f\"Object: {name}, Confidence: {confidence}\")\n","    print(f\"Bounding box coordinates: ({x1}, {y1}), ({x2}, {y2})\")"],"metadata":{"id":"JZH6MRkEEnLk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["img_cv = cv2.imread('/content/ObjectDetect-1/valid/images/054376_jpg.rf.89624a42c6101480f64b20371c70a8fe.jpg')\n","\n","for index, row in df.iterrows():\n","    x1, y1, x2, y2 = int(row['xmin']), int(row['ymin']), int(row['xmax']), int(row['ymax'])\n","\n","    # 객체 영역에 블러 적용\n","    roi = img_cv[y1:y2, x1:x2]\n","    blurred_roi = cv2.GaussianBlur(roi, (99, 99), 0)\n","    img_cv[y1:y2, x1:x2] = blurred_roi\n","\n","    # 바운딩 박스 및 텍스트 추가\n","    cv2.rectangle(img_cv, (x1, y1), (x2, y2), (255, 0, 0), 2)\n","    cv2.putText(img_cv, row['name'], (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (36,255,12), 2)\n","\n","# 이미지 출력\n","cv2_imshow(img_cv)"],"metadata":{"id":"gYoladQZEv15"},"execution_count":null,"outputs":[]}]}